{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6/notebook#1.-Introduction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv(\"../digit_recognition/train (2).csv\")\n",
    "test = pd.read_csv(\"../digit_recognition/test (2).csv\")\n",
    "############################################################### eza ana bade sawer ra2m\n",
    "###############################################################aa= pd.read_csv(\"../digit_recognition/eza.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=train[\"label\"]\n",
    "X_train =train.drop(labels =[\"label\"],axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization cz it converge faster\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "###################################################################aa=aa/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "##################################################################aa = aa.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[2][:,:,0])\n",
    "################################################################## g= plt.imshow(aa[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      " - 107s - loss: 0.4805 - acc: 0.8467 - val_loss: 0.0760 - val_acc: 0.9779\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= model.predict(test)\n",
    "########################################################3results=model.predict(aa)\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2\n",
      "1        0\n",
      "2        9\n",
      "3        0\n",
      "4        3\n",
      "5        7\n",
      "6        0\n",
      "7        3\n",
      "8        0\n",
      "9        3\n",
      "10       5\n",
      "11       7\n",
      "12       4\n",
      "13       0\n",
      "14       4\n",
      "15       3\n",
      "16       3\n",
      "17       1\n",
      "18       9\n",
      "19       0\n",
      "20       9\n",
      "21       1\n",
      "22       1\n",
      "23       5\n",
      "24       7\n",
      "25       4\n",
      "26       2\n",
      "27       7\n",
      "28       4\n",
      "29       7\n",
      "        ..\n",
      "27970    5\n",
      "27971    0\n",
      "27972    4\n",
      "27973    8\n",
      "27974    0\n",
      "27975    3\n",
      "27976    6\n",
      "27977    0\n",
      "27978    1\n",
      "27979    9\n",
      "27980    3\n",
      "27981    1\n",
      "27982    1\n",
      "27983    0\n",
      "27984    4\n",
      "27985    5\n",
      "27986    2\n",
      "27987    2\n",
      "27988    9\n",
      "27989    6\n",
      "27990    7\n",
      "27991    6\n",
      "27992    1\n",
      "27993    9\n",
      "27994    7\n",
      "27995    9\n",
      "27996    7\n",
      "27997    3\n",
      "27998    9\n",
      "27999    2\n",
      "Name: Label, Length: 28000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
